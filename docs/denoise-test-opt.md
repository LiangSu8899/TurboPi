# PI0.5 æ¨ç†ä¼˜åŒ–å®Œæ•´æ–¹æ¡ˆ

**æœ€åæ›´æ–°**: 2026-02-13
**å¹³å°**: NVIDIA Jetson Thor (SM110, Blackwell GB10B)
**Docker**: turbo_pi_eval

---

## ğŸ¯ æœ€ä¼˜æ–¹æ¡ˆæ€»è§ˆ

### å½“å‰æœ€ä½³é…ç½®

| ç»„ä»¶ | æŠ€æœ¯ | å»¶è¿Ÿ | å æ¯” |
|------|------|------|------|
| Vision Encoder | **TRT FP16** | 17 ms | 14.8% |
| VLM KV Cache (18å±‚) | **MLP-only TRT FP8** | 54 ms | 47.0% |
| Denoise (10æ­¥) | **TRT FP8** | 44 ms | 38.3% |
| **Total** | - | **~115 ms** | 100% |
| **Frequency** | - | **~8.7 Hz** | - |

### å¯è§†åŒ–

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     10 Steps: ~115ms (8.7 Hz)                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Vision   â”‚        VLM KV Cache             â”‚          Denoise              â”‚
â”‚ TRT FP16 â”‚        MLP-only TRT FP8         â”‚          TRT FP8              â”‚
â”‚  14.8%   â”‚           47.0%                 â”‚           38.3%               â”‚
â”‚  17 ms   â”‚           54 ms                 â”‚           44 ms               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ä¼˜åŒ–å†ç¨‹

| ç‰ˆæœ¬ | Denoise | Total | é¢‘ç‡ | ä¼˜åŒ–æŠ€æœ¯ |
|------|---------|-------|------|----------|
| v1 (Baseline) | 186 ms | 260 ms | 3.8 Hz | PyTorch BF16 |
| v2 (SDPA no-mask) | 109 ms | 180 ms | 5.6 Hz | SDPA æ—  mask |
| v3 (CUDA Graph) | 98 ms | 170 ms | 5.9 Hz | CUDA Graph æ•è· |
| **v4 (TRT FP8)** | **44 ms** | **~115 ms** | **8.7 Hz** | **Torch-TRT FP8** |

---

## 1. å„ç»„ä»¶è¯¦ç»†é…ç½®

### 1.1 Vision Encoder (TRT FP16)

| å‚æ•° | å€¼ |
|------|-----|
| æ¨¡å‹ | SigLIP |
| ç²¾åº¦ | FP16 |
| ç¼–è¯‘æ–¹å¼ | torch_tensorrt |
| å»¶è¿Ÿ | 17 ms |

### 1.2 VLM KV Cache (MLP-only TRT FP8)

| å‚æ•° | å€¼ |
|------|-----|
| å±‚æ•° | 18 å±‚ PaliGemma |
| MLP | TRT FP8 (ModelOpt + Torch-TRT) |
| Attention | PyTorch SDPA (no-mask) |
| RMSNorm | PyTorch (FP32 variance) |
| å»¶è¿Ÿ | 54 ms |

**å…³é”®æ–‡ä»¶**: `openpi/src/openpi/inference/torch_trt_fp8_kv_cache.py`

### 1.3 Denoise (TRT FP8)

| å‚æ•° | å€¼ |
|------|-----|
| å±‚æ•° | 18 å±‚ Gemma Expert |
| æ­¥æ•° | 10 æ­¥ |
| ç²¾åº¦ | FP8 (Torch-TRT) |
| åŠ é€Ÿæ¯” | 3.11x vs FP16 |
| ä½™å¼¦ç›¸ä¼¼åº¦ | 0.981 |
| å»¶è¿Ÿ | 44 ms |

**å…³é”®æ–‡ä»¶**: `openpi/scripts/denoise_torch_trt_static.py`

---

## 2. Denoise TRT FP8 å®ç°ç»†èŠ‚

### 2.1 ç¼–è¯‘å‘½ä»¤

```bash
docker exec -it turbo_pi_eval python /workspace/scripts/denoise_torch_trt_static.py \
    --checkpoint_dir /root/.cache/openpi/checkpoints/pi05_libero \
    --output_path /workspace/denoise_trt_static \
    --precision fp8 \
    --compile_loop \
    --benchmark
```

### 2.2 å…³é”®æŠ€æœ¯

```python
# 1. FP8 é‡åŒ– (ModelOpt)
module_fp8 = mtq.quantize(module, mtq.FP8_DEFAULT_CFG, forward_loop=calibrate)

# 2. Torch-TRT ç¼–è¯‘ (å…³é”®ï¼šä½¿ç”¨ export_torch_mode)
with export_torch_mode():
    trt_module = torch_tensorrt.compile(
        module_fp8,
        inputs=example_inputs,
        enabled_precisions={torch.float16, torch.float8_e4m3fn},
        workspace_size=8 << 30,
    )
```

### 2.3 ç²¾åº¦ä¿æŠ¤

| æ“ä½œ | ç²¾åº¦ | åŸå›  |
|------|------|------|
| Softmax | **FP32** | é˜²æ­¢ FP16 ä¸‹æº¢å˜ 0 |
| RMSNorm variance | **FP32** | æ•°å€¼ç¨³å®šæ€§ |
| RoPE | **FP32** | é¿å…ç´¯ç§¯è¯¯å·® |

### 2.4 Benchmark ç»“æœ

| é…ç½® | 10æ­¥æ—¶é—´ | åŠ é€Ÿæ¯” | ä½™å¼¦ç›¸ä¼¼åº¦ |
|------|---------|--------|-----------|
| Original (FP16) | 136.74 ms | 1x | - |
| **TRT FP8** | **43.92 ms** | **3.11x** | **0.981** |
| CUDA Graph BF16 (æ—§) | 109 ms | 1.25x | - |

---

## 3. æµ‹è¯•é…ç½®

| é…ç½®é¡¹ | å€¼ |
|--------|-----|
| Denoising Steps | 10 |
| Warmup | 3 iterations |
| Profile Iterations | 10 |
| Checkpoint | pi05_libero |
| Batch Size | 1 |
| Prefix Length | 968 tokens |
| Action Horizon | 50 |

---

## 4. VLM KV Cache å†…éƒ¨åˆ†è§£ (MLP-only TRT FP8)

### 4.1 ç»„ä»¶å»¶è¿Ÿä¼°ç®—

| å­ç»„ä»¶ | æŠ€æœ¯ | ä¼°è®¡è€—æ—¶ | ä¼˜åŒ–çŠ¶æ€ |
|--------|------|----------|----------|
| **MLP (18å±‚)** | TRT FP8 âœ… | ~35 ms | âœ… å·²ä¼˜åŒ– (2.94x) |
| **Attention SDPA** | PyTorch | ~12 ms | ğŸ”¶ å¯æ¢ç´¢ |
| **RoPE (18å±‚)** | PyTorch | ~3 ms | ğŸ”¶ å¯é¢„è®¡ç®— |
| **RMSNorm (36æ¬¡)** | PyTorch (FP32) | ~2 ms | ğŸ”¶ å¯èåˆ |
| **dtype è½¬æ¢** | BF16â†”FP16 | ~2 ms | ğŸ”¶ å¯å‡å°‘ |

### 4.2 MLP TRT FP8 åŠ é€Ÿæ•ˆæœ

| é…ç½® | å»¶è¿Ÿ | åŠ é€Ÿæ¯” |
|------|------|--------|
| PyTorch FP16 | 59.89 ms | 1x |
| PyTorch native FP8 | ~60 ms | æ— åŠ é€Ÿ |
| **Torch-TRT FP8** | **20.39 ms** | **2.94x** |

### 4.3 VLM å…¨å±‚ TRT æµ‹è¯•ç»“æœ (å·²éªŒè¯ä¸å¯è¡Œ)

| æ–¹æ¡ˆ | é…ç½® | å»¶è¿Ÿ | é—®é¢˜ |
|------|------|------|------|
| å…¨ 18 å±‚ TRT FP8 | å…¨å±‚ç¼–è¯‘ | NaN | FP8 + BF16 ä¸å…¼å®¹ |
| å…¨ 18 å±‚ TRT BF16 | å…¨å±‚ç¼–è¯‘ | 49.9 ms | Layer 16 overflow |
| 15 å±‚ TRT + 3 å±‚ PyTorch | åˆ†æ®µç¼–è¯‘ | 56.9 ms | âœ… å¯è¡Œä½†æ— ä¼˜åŠ¿ |
| **MLP-only TRT FP8** | å½“å‰æ–¹æ¡ˆ | **54 ms** | **âœ… æœ€ä¼˜** |

**ç»“è®º**: MLP-only TRT FP8 æ˜¯å½“å‰æœ€ä¼˜æ–¹æ¡ˆï¼Œå…¨å±‚ç¼–è¯‘æ— æ˜æ˜¾ä¼˜åŠ¿ã€‚

---

## 5. è¿›ä¸€æ­¥ä¼˜åŒ–ç©ºé—´åˆ†æ

### 5.1 VLM KV Cache ä¼˜åŒ–ç‚¹ (~54 ms)

| ä¼˜åŒ–é¡¹ | æ–¹æ³• | é¢„è®¡æ”¶ç›Š | ä¼˜å…ˆçº§ |
|--------|------|----------|--------|
| RoPE é¢„è®¡ç®— | ä¸€æ¬¡è®¡ç®—ï¼Œ18å±‚å¤ç”¨ | 2-3 ms | ğŸ”¶ ä¸­ |
| dtype ç»Ÿä¸€ | å…¨ç¨‹ FP16 é¿å…è½¬æ¢ | 1-2 ms | ğŸ”¶ ä¸­ |
| RMSNorm èåˆ | NVIDIA fused kernel | ~1 ms | ğŸ”¶ ä¸­ |
| Attention ä¼˜åŒ– | Flash Attention 2 | 3-5 ms | ğŸ”¶ ä¸­ |

### 5.2 Vision ä¼˜åŒ–ç‚¹ (~17 ms)

| ä¼˜åŒ–é¡¹ | æ–¹æ³• | é¢„è®¡æ”¶ç›Š | ä¼˜å…ˆçº§ |
|--------|------|----------|--------|
| Vision TRT FP8 | FP16 â†’ FP8 | 5-8 ms | ğŸŸ¡ ä½ |

### 5.3 Denoise ä¼˜åŒ–ç‚¹ (å·²å®Œæˆä¸»è¦ä¼˜åŒ–)

| ä¼˜åŒ–é¡¹ | æ–¹æ³• | çŠ¶æ€ |
|--------|------|------|
| TRT FP8 | Torch-TRT ç¼–è¯‘ | âœ… å®Œæˆ (3.11x) |
| SDPA no-mask | å»é™¤ attention mask | âœ… å®Œæˆ (2.8x) |

---

## 6. å…³é”®æ–‡ä»¶ç´¢å¼•

### 6.1 å®ç°æ–‡ä»¶

| æ–‡ä»¶ | åŠŸèƒ½ |
|------|------|
| `inference/torch_trt_fp8_kv_cache.py` | VLM KV Cache TRT FP8 MLP |
| `scripts/denoise_torch_trt_static.py` | **Denoise TRT FP8 ç¼–è¯‘** |
| `modules/denoise_trt.py` | Denoise TRT æ¨ç†å°è£… |
| `modules/trt_prefill.py` | VLM TRT å°è£… |
| `modules/vision_trt.py` | Vision TRT å°è£… |

### 6.2 æ–‡æ¡£æ–‡ä»¶

| æ–‡ä»¶ | å†…å®¹ |
|------|------|
| `openpi/docs/debug-10-attention-optimization.md` | SDPA ä¼˜åŒ–è¯¦æƒ… |
| `openpi/docs/debug-11-cuda-graph-optimization.md` | CUDA Graph å®ç° |
| `openpi/docs/debug-12-nvidia-comparison.md` | **Denoise TRT FP8 å®ç°** |

---

## 7. å¹³å°è§„æ ¼

### 7.1 Thor GPU å±æ€§

```
============================================================
Thor GPU Properties
============================================================
Name: NVIDIA Thor
Total Memory: 122.8 GB
L2 Cache Size: 32.0 MB
Compute Capability: 11.0 (SM110)
Multiprocessors: 20

FP8 TFLOPS: 1920 (vs BF16: 960)
============================================================
```

### 7.2 æ¨¡å‹å‚æ•°

| ç»„ä»¶ | å‚æ•°é‡ | FP8 (MB) |
|------|--------|----------|
| PaliGemma LLM | ~2B | ~1000 |
| Gemma Expert | 691M | 659 |
| - MLP (18å±‚) | 226M | 216 |
| - Attention | 85M | 81 |
| SigLIP Vision | 400M | ~400 |

---

## 8. ä¸‹ä¸€æ­¥ä¼˜åŒ–æ–¹å‘

### 8.1 çŸ­æœŸ (é¢„è®¡ 5-10 ms æå‡)

| ä¼˜åŒ– | æ–¹æ³• | ç›®æ ‡ |
|------|------|------|
| RoPE é¢„è®¡ç®— | ç¼“å­˜ cos/sin | å‡å°‘ ~3 ms |
| dtype ç»Ÿä¸€ | é¿å… BF16â†”FP16 | å‡å°‘ ~2 ms |

### 8.2 ä¸­æœŸ (é¢„è®¡ 10-20 ms æå‡)

| ä¼˜åŒ– | æ–¹æ³• | ç›®æ ‡ |
|------|------|------|
| Vision FP8 | TRT FP8 ç¼–è¯‘ | 17 ms â†’ 10 ms |
| Kernel èåˆ | RMSNorm + Linear | å‡å°‘ launch å¼€é”€ |

### 8.3 é•¿æœŸ

| ä¼˜åŒ– | æ–¹æ³• | ç›®æ ‡ |
|------|------|------|
| å…¨å›¾ TRT | NVIDIA æ–¹æ¡ˆ | 80 ms (12.5 Hz) |
| æ­¥æ•°å‡å°‘ | 1-step diffusion | æå¤§æå‡ |

---

## 9. æ€»ç»“

### å½“å‰çŠ¶æ€

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  PI0.5 æ¨ç†å»¶è¿Ÿ: ~115 ms (8.7 Hz)                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Vision   â”‚        VLM KV Cache             â”‚          Denoise              â”‚
â”‚ TRT FP16 â”‚        MLP-only TRT FP8         â”‚          TRT FP8              â”‚
â”‚  17 ms   â”‚           54 ms                 â”‚           44 ms               â”‚
â”‚  âœ…      â”‚           âœ… MLPå·²ä¼˜åŒ–           â”‚           âœ… 3.11x            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ä¸ NVIDIA æ–¹æ¡ˆå¯¹æ¯”

| æŒ‡æ ‡ | æˆ‘ä»¬çš„æ–¹æ¡ˆ | NVIDIA å…¨å›¾ TRT |
|------|-----------|-----------------|
| å»¶è¿Ÿ | ~115 ms | ~80 ms |
| é¢‘ç‡ | 8.7 Hz | 12.5 Hz |
| å¤æ‚åº¦ | åˆ†æ¨¡å—ï¼Œæ˜“è°ƒè¯• | å•å›¾ï¼Œé»‘ç›’ |
| å·®è· | - | 35 ms |

### æ¨è

**ç»§ç»­ä½¿ç”¨å½“å‰åˆ†æ¨¡å— TRT FP8 æ–¹æ¡ˆ**ï¼Œå·²è¾¾åˆ° 8.7 Hzï¼Œæ¥è¿‘ 10 Hz ç›®æ ‡ã€‚å¦‚éœ€è¿›ä¸€æ­¥ä¼˜åŒ–ï¼Œä¼˜å…ˆå°è¯• RoPE é¢„è®¡ç®—å’Œ Vision FP8ã€‚
